name: Feature processing
description: calculate features for our machine learning model
inputs:
- {name: raw_data_path, type: String}
- {name: feature_data_path, type: String}
- {name: year_from, type: Integer}
outputs:
- {name: Output, type: String}
implementation:
  container:
    image: python:3.7
    command:
    - sh
    - -c
    - (PIP_DISABLE_PIP_VERSION_CHECK=1 python3 -m pip install --quiet --no-warn-script-location
      'fastparquet' 'fsspec' 'gcsfs' || PIP_DISABLE_PIP_VERSION_CHECK=1 python3 -m
      pip install --quiet --no-warn-script-location 'fastparquet' 'fsspec' 'gcsfs'
      --user) && "$0" "$@"
    - python3
    - -u
    - -c
    - |
      def feature_processing(raw_data_path, feature_data_path, year_from):
          '''calculate features for our machine learning model'''
          import pandas as pd
          from datetime import datetime

          # read dataframe
          sp500_df = pd.read_parquet(raw_data_path)

          # create empty df to store feature
          sp500_feautres_df = pd.DataFrame()

          average_days_window_closing_price = [5, 30, 120, 365]
          # average price for window of different days
          for window in average_days_window_closing_price:
              sp500_feautres_df['Close__rolling_mean__'+str(window)+'_days'] = sp500_df['Close'].rolling(window).mean().shift(periods=1)
              sp500_feautres_df['Close__rolling_std__'+str(window)+'_days'] = sp500_df['Close'].rolling(window).std().shift(periods=1)
              sp500_feautres_df['Close__rolling_max__'+str(window)+'_days'] = sp500_df['Close'].rolling(window).max().shift(periods=1)
              sp500_feautres_df['Close__rolling_min__'+str(window)+'_days'] = sp500_df['Close'].rolling(window).min().shift(periods=1)
              sp500_feautres_df['Close__rolling_range__'+str(window)+'_days'] = sp500_feautres_df['Close__rolling_max__'+str(window)+'_days'] - sp500_feautres_df['Close__rolling_min__'+str(window)+'_days']

          average_days_window_volume = [5, 10, 15]
          # average price for window of different days
          for window in average_days_window_volume:
              sp500_feautres_df['Volume__rolling_max__'+str(window)+'_days'] = sp500_df['Close'].rolling(window).max().shift(periods=1)
              sp500_feautres_df['Volume__rolling_sum__'+str(window)+'_days'] = sp500_df['Close'].rolling(window).sum().shift(periods=1)

          # get day of the week
          sp500_df['day_of_week'] = sp500_df.index.dayofweek
          # get quarter
          sp500_df['quarter'] = sp500_df.index.quarter

          sp500_feautres_df = pd.concat([sp500_feautres_df, pd.get_dummies(sp500_df['day_of_week'], prefix='day_of_week')], 1)
          sp500_feautres_df = pd.concat([sp500_feautres_df, pd.get_dummies(sp500_df['day_of_week'], prefix='quarter')], 1)

          # let's not confuse our model from data from way back
          sp500_feautres_df = sp500_feautres_df[sp500_feautres_df.index > datetime(year=1990, month=12, day=31)]
          # get label for feature dataset
          sp500_timeboxed_feautres_df = pd.merge(sp500_df['Close'], sp500_feautres_df, left_index=True, right_index=True)
          # write out to parquet
          sp500_timeboxed_feautres_df.to_parquet(feature_data_path, compression='GZIP')
          features_numbers = len(sp500_timeboxed_feautres_df.columns) - 1
          total_days = len(sp500_timeboxed_feautres_df)
          print('Writing %s features for %s days' % (features_numbers, total_days))
          print('Done!')

          return feature_data_path

      def _serialize_str(str_value: str) -> str:
          if not isinstance(str_value, str):
              raise TypeError('Value "{}" has type "{}" instead of str.'.format(str(str_value), str(type(str_value))))
          return str_value

      import argparse
      _parser = argparse.ArgumentParser(prog='Feature processing', description='calculate features for our machine learning model')
      _parser.add_argument("--raw-data-path", dest="raw_data_path", type=str, required=True, default=argparse.SUPPRESS)
      _parser.add_argument("--feature-data-path", dest="feature_data_path", type=str, required=True, default=argparse.SUPPRESS)
      _parser.add_argument("--year-from", dest="year_from", type=int, required=True, default=argparse.SUPPRESS)
      _parser.add_argument("----output-paths", dest="_output_paths", type=str, nargs=1)
      _parsed_args = vars(_parser.parse_args())
      _output_files = _parsed_args.pop("_output_paths", [])

      _outputs = feature_processing(**_parsed_args)

      _outputs = [_outputs]

      _output_serializers = [
          _serialize_str,

      ]

      import os
      for idx, output_file in enumerate(_output_files):
          try:
              os.makedirs(os.path.dirname(output_file))
          except OSError:
              pass
          with open(output_file, 'w') as f:
              f.write(_output_serializers[idx](_outputs[idx]))
    args:
    - --raw-data-path
    - {inputValue: raw_data_path}
    - --feature-data-path
    - {inputValue: feature_data_path}
    - --year-from
    - {inputValue: year_from}
    - '----output-paths'
    - {outputPath: Output}
