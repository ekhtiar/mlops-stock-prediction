name: Hyp tune train rf
description: random search with cross validation to find the best parameters for our
  random forest
inputs:
- {name: feature_data_path, type: String}
- {name: tuned_model_path, type: String}
- {name: holdout_days, type: Integer}
- {name: random_iterations, type: Integer}
- {name: random_params, type: String}
outputs:
- {name: Output, type: String}
implementation:
  container:
    image: python:3.7
    command:
    - sh
    - -c
    - (PIP_DISABLE_PIP_VERSION_CHECK=1 python3 -m pip install --quiet --no-warn-script-location
      'scikit-learn' 'fastparquet' 'fsspec' 'gcsfs' 'google-cloud-storage' || PIP_DISABLE_PIP_VERSION_CHECK=1
      python3 -m pip install --quiet --no-warn-script-location 'scikit-learn' 'fastparquet'
      'fsspec' 'gcsfs' 'google-cloud-storage' --user) && "$0" "$@"
    - python3
    - -u
    - -c
    - "def hyp_tune_train_rf(feature_data_path, tuned_model_path,\n              \
      \        holdout_days, random_iterations, random_params):\n    '''random search\
      \ with cross validation to find the best parameters for our random forest'''\n\
      \    import json\n    import pandas as pd\n    from datetime import datetime,\
      \ timedelta\n    import _pickle as cPickle # save ML model\n    from google.cloud\
      \ import storage # save the model to GCS\n    from sklearn.ensemble import RandomForestRegressor\n\
      \    from sklearn.metrics import mean_absolute_error, mean_squared_error\n \
      \   from sklearn.model_selection import train_test_split\n    from sklearn.model_selection\
      \ import RandomizedSearchCV\n    from sklearn.model_selection import GridSearchCV\n\
      \    from urllib.parse import urlparse\n\n    # read dataframe\n    sp500_timeboxed_feautres_df\
      \ = pd.read_parquet(feature_data_path)\n\n    # this will be our training set\n\
      \    sp500_train_df = sp500_timeboxed_feautres_df[sp500_timeboxed_feautres_df.index\
      \ < (datetime.today() - timedelta(days=holdout_days))]\n\n    # get x and y\n\
      \    x_train, y_train = sp500_train_df.drop('Close', axis=1), sp500_train_df['Close']\n\
      \    # split the data for initial testing\n    X_train, X_test, Y_train, Y_test\
      \ = train_test_split(x_train, y_train, test_size=0.2,random_state=786)\n\n \
      \   # create random grid\n    random_grid = json.loads(random_params)\n\n  \
      \  # train the model\n    rf = RandomForestRegressor()\n    # Random search\
      \ of parameters, using 3 fold cross validation and search across 100 different\
      \ combinations\n    rf_random = RandomizedSearchCV(estimator = rf, param_distributions\
      \ = random_grid, n_iter = random_iterations, cv = 3, verbose=2, random_state=42,\
      \ n_jobs = -1)\n    # Fit the random search model\n    rf_random.fit(x_train,\
      \ y_train) # since we will use CV, we don't need to split data to train and\
      \ test\n\n    # some initial testing\n    predictions_tuned_rf = rf_random.predict(X_test)\n\
      \    mae_score = mean_absolute_error(Y_test, predictions_tuned_rf)\n    mse_score\
      \ = mean_squared_error(Y_test, predictions_tuned_rf)\n    print('mean absolute\
      \ error without optimization: %s' % mae_score)\n    print('mean squared error\
      \ without optimization is: %s' % mse_score) \n\n    temp_model_path = '/tmp/model.pickle'\n\
      \n    # write out output\n    # save the model into temp\n    with open(temp_model_path,\
      \ 'wb') as f:\n        cPickle.dump(rf_random.best_estimator_, f, -1)\n\n  \
      \  # get client and write to GCS\n    # parse model write path for GS\n    parse\
      \ = urlparse(url=tuned_model_path, allow_fragments=False)\n\n    if parse.path[0]\
      \ =='/':\n        model_path = parse.path[1:]\n    client = storage.Client()\n\
      \    bucket = client.get_bucket(parse.netloc)\n    model = bucket.blob(model_path)\n\
      \    model.upload_from_filename(temp_model_path)\n\n    return tuned_model_path\n\
      \ndef _serialize_str(str_value: str) -> str:\n    if not isinstance(str_value,\
      \ str):\n        raise TypeError('Value \"{}\" has type \"{}\" instead of str.'.format(str(str_value),\
      \ str(type(str_value))))\n    return str_value\n\nimport argparse\n_parser =\
      \ argparse.ArgumentParser(prog='Hyp tune train rf', description='random search\
      \ with cross validation to find the best parameters for our random forest')\n\
      _parser.add_argument(\"--feature-data-path\", dest=\"feature_data_path\", type=str,\
      \ required=True, default=argparse.SUPPRESS)\n_parser.add_argument(\"--tuned-model-path\"\
      , dest=\"tuned_model_path\", type=str, required=True, default=argparse.SUPPRESS)\n\
      _parser.add_argument(\"--holdout-days\", dest=\"holdout_days\", type=int, required=True,\
      \ default=argparse.SUPPRESS)\n_parser.add_argument(\"--random-iterations\",\
      \ dest=\"random_iterations\", type=int, required=True, default=argparse.SUPPRESS)\n\
      _parser.add_argument(\"--random-params\", dest=\"random_params\", type=str,\
      \ required=True, default=argparse.SUPPRESS)\n_parser.add_argument(\"----output-paths\"\
      , dest=\"_output_paths\", type=str, nargs=1)\n_parsed_args = vars(_parser.parse_args())\n\
      _output_files = _parsed_args.pop(\"_output_paths\", [])\n\n_outputs = hyp_tune_train_rf(**_parsed_args)\n\
      \n_outputs = [_outputs]\n\n_output_serializers = [\n    _serialize_str,\n\n\
      ]\n\nimport os\nfor idx, output_file in enumerate(_output_files):\n    try:\n\
      \        os.makedirs(os.path.dirname(output_file))\n    except OSError:\n  \
      \      pass\n    with open(output_file, 'w') as f:\n        f.write(_output_serializers[idx](_outputs[idx]))\n"
    args:
    - --feature-data-path
    - {inputValue: feature_data_path}
    - --tuned-model-path
    - {inputValue: tuned_model_path}
    - --holdout-days
    - {inputValue: holdout_days}
    - --random-iterations
    - {inputValue: random_iterations}
    - --random-params
    - {inputValue: random_params}
    - '----output-paths'
    - {outputPath: Output}
